name: Build/Test

on:
  workflow_call:

jobs:
  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Install dependencies
        run: python3 -m pip install tox
      - name: Run linters
        run: tox -e pep8

  unit-test:
    name: Unit tests
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Install dependencies
        run: python -m pip install tox
      - name: Run tests
        run: tox -e py3

  build:
    name: Build the charm
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
      - name: Setup LXD
        uses: canonical/setup-lxd@v0.1.1
        with:
          channel: 5.21/stable
      - name: Build charm(s)
        id: builder
        run: |
          sudo snap install charmcraft --classic
          charmcraft pack -v
          ./rename.sh
      - name: Upload built charm
        uses: actions/upload-artifact@v4
        with:
          name: charms
          path: "*.charm"

  functional-test:
    needs:
      - lint
      - unit-test
      - build
    name: Functional test
    runs-on: [self-hosted, large, ubuntu-24.04, amd64]
    steps:

      - name: Download charm
        uses: actions/download-artifact@v4
        with:
          name: charms
          path: ~/artifacts/

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install sunbeam
        run: |
          date
          sudo snap install openstack --channel 2024.1
          sunbeam prepare-node-script | bash -x
          sudo snap refresh juju --channel 3.4/stable
          sg snap_daemon "sunbeam cluster bootstrap --accept-defaults"
          sg snap_daemon "sunbeam cluster list"
          juju status -m admin/controller
          juju status -m openstack
          date

      - name: Get actionutils
        run: |
          curl -sL https://raw.githubusercontent.com/canonical/microceph/main/tests/scripts/actionutils.sh -o ~/actionutils.sh
          chmod +x ~/actionutils.sh

      - name: Upgrade to locally built charm
        run: |
          juju refresh microceph --path ~/artifacts/microceph.charm
          juju add-unit -m admin/controller microceph --to 0
          # Wait for unit to show up
          for i in $( seq 1 20 ) ; do
              if juju status -m admin/controller | grep -E 'microceph/.*active.*idle' ; then
                  echo "microceph unit active"; break
              else
                  echo -n "." ; sleep 4
              fi
          done
          sudo snap list
          juju status -m admin/controller
          # TODO: We can't upgrade the snap via the charm yet, do it by hand
          sudo snap refresh microceph --channel=reef/edge

      - name: Add disks
        run: |
          set -eux
          juju run microceph/0 add-osd loop-spec=4G,3
          sudo microceph.ceph -s
          ~/actionutils.sh wait_for_osds 3
          sudo microceph.ceph -s

      - name: Enable RGW
        run: |
          set -eux
          juju config microceph enable-rgw="*"
          ~/actionutils.sh wait_for_rgw 1

      - name: Collect logs
        if: failure()
        run: ./tests/scripts/ci_helpers.sh collect_sunbeam_and_microceph_logs

      - name: Upload logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: microceph_juju_functional_test_logs
          path: logs
          retention-days: 30

      - name: Setup tmate session
        if: ${{ failure() && runner.debug }}
        uses: canonical/action-tmate@main

  juju-cluster-test:
    needs:
      - lint
      - unit-test
      - build
    name: Juju cluster test
    runs-on: [self-hosted, xlarge]
    steps:

      - name: Download charm
        uses: actions/download-artifact@v4
        with:
          name: charms
          path: ~/artifacts/

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup LXD
        uses: canonical/setup-lxd@v0.1.1
        with:
          # pin lxd to LTS release.
          channel: 5.21/stable

      - name: Install dependencies
        run: ./tests/scripts/ci_helpers.sh install_deps

      - name: Install MicroCeph charm
        run: |
          date
          juju deploy -n 3 ~/artifacts/microceph.charm --config default-pool-size=1
          ./tests/scripts/ci_helpers.sh wait_for_microceph_bootstrap
          date

      - name: Show Juju status
        run: |
          set -eux
          juju status

      - name: Add disks
        run: |
          set -eux
          juju run microceph/0 add-osd loop-spec=4G,1 --wait=2m
          juju run microceph/1 add-osd loop-spec=4G,1 --wait=2m
          juju run microceph/2 add-osd loop-spec=4G,1 --wait=2m

      - name: Remove Unit
        run: |
          set -x
          ./tests/scripts/ci_helpers.sh remove_unit_wait "microceph/2"

      - name: Test mon addresses
        run: |
          curl="sudo curl -s --unix-socket /var/snap/microceph/common/state/control.socket"
          mons=$( ( juju ssh microceph/0 "$curl http://localhost/1.0/services/mon | \
            jq -r '.metadata.addresses[]' | wc -l" ) )
          if [[ $mons -ne 2 ]] ; then
            echo "Expected 2 MONs, got $mons. MON status: "
            $curl http://localhost/1.0/services/mon
            exit 1
          fi

      - name: Collect logs
        if: failure()
        run: ./tests/scripts/ci_helpers.sh collect_microceph_logs

      - name: Upload logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: microceph_juju_cluster_test_logs
          path: logs
          retention-days: 30

      - name: Setup tmate session
        if: ${{ failure() && runner.debug }}
        uses: canonical/action-tmate@main

  juju-cluster-maintenance-test:
    needs:
      - lint
      - unit-test
      - build
    name: Juju cluster maintenance test
    runs-on: [self-hosted, xlarge]
    steps:

      - name: Download charm
        uses: actions/download-artifact@v4
        with:
          name: charms
          path: ~/artifacts/

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup LXD
        uses: canonical/setup-lxd@v0.1.1
        with:
          # pin lxd to LTS release.
          channel: 5.21/stable

      - name: Install dependencies
        run: ./tests/scripts/ci_helpers.sh install_deps

      - name: Install MicroCeph charm
        run: |
          date
          # FIXME: change to squid/stable when maintenance feature is landed
          juju deploy -n 4 ~/artifacts/microceph.charm --config snap-channel=squid/edge
          ./tests/scripts/ci_helpers.sh wait_for_microceph_bootstrap
          date

      - name: Show Juju status
        run: |
          set -eux
          juju status

      - name: Enable one extra ceph mon for redundancy
        run: |
          set -eux

          echo "Make sure all units have ceph monitor enabled."

          for i in 0 1 2 3 ; do
            juju ssh microceph/$i -- sudo microceph enable mon || true
          done

      - name: Add disks
        run: |
          set -eux
          juju run microceph/0 add-osd loop-spec=4G,1 --wait=2m
          juju run microceph/1 add-osd loop-spec=4G,1 --wait=2m
          juju run microceph/2 add-osd loop-spec=4G,1 --wait=2m
          juju run microceph/3 add-osd loop-spec=4G,1 --wait=2m

      - name: Show Ceph status
        run: |
          set -eux
          juju ssh microceph/0 -- sudo microceph status
          juju ssh microceph/0 -- sudo microceph.ceph -s

      - name: Assert Ceph is in healthy state before running test
        run: |
          set -eux
          juju ssh microceph/0 -- sudo microceph.ceph health | grep HEALTH_OK

      - name: Dry run test
        run: |
          set -eux

          echo "Test dry running enter-maintenance and exit-maintenance actions."

          result=$(juju run microceph/0 exit-maintenance dry-run=true --format json)
          echo $result

          action_counts=$(echo $result | jq '."microceph/0".results.actions | length')
          if [ "$action_counts" != "3" ] ; then
            echo "Expect dry run exit-maintenance to produce 3 steps."
            exit 1
          fi

          result=$(juju run microceph/0 enter-maintenance dry-run=true --format json)
          echo $result

          action_counts=$(echo $result | jq '."microceph/0".results.actions | length')
          if [ "$action_counts" != "4" ] ; then
            echo "Expect dry run enter-maintenance to produce 3 steps."
            exit 1
          fi

      - name: Test enter maintenance mode okay
        run: |
          set -eux

          echo "Test running enter-maintenance action."

          result=$(juju run microceph/3 enter-maintenance stop-osds=true --format json)
          echo $result

          status=$(echo $result | jq '."microceph/3".results.status' -r )
          if [ "$status" != "success" ] ; then
            echo "Expect enter-maintenance to succeed."
            exit 1
          fi

          if ! $(juju ssh microceph/3 -- sudo microceph.ceph osd dump | grep noout > /dev/null 2>&1) ; then
            echo "Expect osd noout is set"
            exit 1
          fi

          if ! $(juju ssh microceph/3 -- snap services microceph.osd | grep inactive > /dev/null 2>&1) ; then
            echo "Expect osd service is inactive"
            exit 1
          fi

          if ! $(juju ssh microceph/3 -- snap services microceph.osd | grep disabled > /dev/null 2>&1) ; then
            echo "Expect osd service is disabled"
            exit 1
          fi

      - name: Test exit maintenance mode okay
        run: |
          set -eux

          echo "Test running exit-maintenance action."

          result=$(juju run microceph/3 exit-maintenance --format json)
          echo $result

          status=$(echo $result | jq '."microceph/3".results.status' -r )
          if [ "$status" != "success" ] ; then
            echo "Expect exit-maintenance to succeed."
            exit 1
          fi

          if $(juju ssh microceph/3 -- sudo microceph.ceph osd dump | grep noout > /dev/null 2>&1) ; then
            echo "Expect osd noout is unset"
            exit 1
          fi

          if ! $(juju ssh microceph/3 -- snap services microceph.osd | grep active > /dev/null 2>&1) ; then
            echo "Expect osd service is active"
            exit 1
          fi

          if ! $(juju ssh microceph/3 -- snap services microceph.osd | grep enabled > /dev/null 2>&1) ; then
            echo "Expect osd service is enabled"
            exit 1
          fi

      - name: Remove Unit
        run: |
          set -x
          ./tests/scripts/ci_helpers.sh remove_unit_wait "microceph/3"

      - name: Test enter maintenance mode fail
        run: |
          set -eux

          echo "Test running enter-maintenance action (fail case)."

          result=$(juju run microceph/2 enter-maintenance stop-osds=true --format json)
          echo $result

          has_errors=$(echo $result | jq '."microceph/2".results.errors != ""')
          if [ "$has_errors" != "true" ] ; then
            echo "Expect enter-maintenance to fail with error message because there is only 3 nodes."
            exit 1
          fi

          status_failure=$(echo $result | jq '."microceph/2".results.status == "failure"')
          if [ "$status_failure" != "true" ] ; then
            echo "Expect enter-maintenance to fail with status=failure."
            exit 1
          fi

      - name: Collect logs
        if: failure()
        run: ./tests/scripts/ci_helpers.sh collect_microceph_logs

      - name: Upload logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: microceph_juju_cluster_test_logs
          path: logs
          retention-days: 30

      - name: Setup tmate session
        if: ${{ failure() && runner.debug }}
        uses: canonical/action-tmate@main

  juju-single-test:
    needs:
      - lint
      - unit-test
      - build
    name: Juju single test
    runs-on: [self-hosted, xlarge]
    steps:

      - name: Download charm
        uses: actions/download-artifact@v4
        with:
          name: charms
          path: ~/artifacts/

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup LXD
        uses: canonical/setup-lxd@v0.1.1
        with:
          # pin lxd to LTS release.
          channel: 5.21/stable

      - name: Install dependencies
        run: ./tests/scripts/ci_helpers.sh install_deps

      - name: Install MicroCeph charm
        run: |
          set -eux
          date
          # constraints to deploy on virtual machine.
          juju deploy ~/artifacts/microceph.charm --storage osd-standalone='2G,3' --constraints="virt-type=virtual-machine root-disk=50G mem=8G"
          # wait for charm to bootstrap and OSD devices to enroll.
          juju wait-for unit microceph/0 --timeout '30m' --query='workload-message=="(workload) charm is ready"'
          bash ./tests/scripts/ci_helpers.sh check_osd_count microceph/0 3
          date

      - name: Remove Juju Storage
        run: |
          set -eux
          juju detach-storage osd-standalone/0
          juju wait-for unit microceph/0 --query='workload-status=="blocked"'
          # wait before completely removing the storage.
          sleep 1m
          juju remove-storage osd-standalone/0
          bash tests/scripts/ci_helpers.sh check_osd_count microceph/0 2
          date

      - name: Add another OSD
        run: |
          set -eux
          juju add-storage microceph/0 osd-standalone='2G,1'
          juju wait-for unit microceph/0 --timeout '20m' --query='workload-message=="(workload) charm is ready"'
          bash tests/scripts/ci_helpers.sh check_osd_count microceph/0 3
          date

      - name: Add and relate RadosGW charm
        run: |
          set -eux
          juju deploy ch:ceph-radosgw
          sleep 120
          juju integrate ceph-radosgw microceph
          sleep 420
          for i in $(seq 1 20); do
            rgwpools=$(juju ssh microceph/0 -- "sudo microceph.ceph osd pool ls")
            if echo "$rgwpools" | grep -E 'rgw' ; then
              echo "Found RadosGW pools"
              break
            else
              echo -n '.'
              sleep 60
            fi
          done
          rgwpools=$(juju ssh microceph/0 -- "sudo microceph.ceph osd pool ls")
          if ! echo "$rgwpools" | grep -E "rgw" ; then
            echo "No RadosGW pools were created"
            juju ssh microceph/0 -- "sudo microceph.ceph osd pool ls"
            juju ssh microceph/0 -- "sudo microceph.ceph -s"
            exit 1
          fi

  juju-upgrade-test:
    needs:
      - lint
      - unit-test
      - build
    name: Juju upgrade test
    runs-on: [self-hosted, xlarge]
    steps:

      - name: Download charm
        uses: actions/download-artifact@v4
        with:
          name: charms
          path: ~/artifacts/

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup LXD
        uses: canonical/setup-lxd@v0.1.1
        with:
          # pin lxd to LTS release.
          channel: 5.21/stable

      - name: Install dependencies
        run: ./tests/scripts/ci_helpers.sh install_deps

      - name: Install MicroCeph charm
        run: |
          date
          juju deploy -n 3 ~/artifacts/microceph.charm --config snap-channel=quincy/stable
          ./tests/scripts/ci_helpers.sh wait_for_microceph_bootstrap
          date

      - name: Show Juju status
        run: |
          set -eux
          juju status

      - name: Test non-existing channel
        run: |
          set -eux
          juju status
          juju config microceph snap-channel="non/exist"
          juju wait-for application microceph --query='status=="blocked"'
          juju status
          juju status blocked | egrep '^microceph/.*Cannot upgrade.*to non/exist'
          # set back
          juju config microceph snap-channel=quincy/stable
          sleep 10

      - name: Test upgrading with unhealthy cluster blocks
        run: |
          set -eux
          juju config microceph snap-channel=quincy/edge
          sleep 10
          juju wait-for application microceph --query='status=="blocked"'
          juju status
          juju status blocked | egrep '^microceph/.*Cannot upgrade, ceph health not ok'
          # Should be in WARN as we don't have OSDs
          juju ssh microceph/0 -- sudo ceph -s
          juju config microceph snap-channel=quincy/stable
          juju wait-for application microceph --query='name=="microceph" && (status=="active" || status=="idle")' --timeout=20m

      - name: Add disks for health
        run: |
          set -eux
          for i in 0 1 2 ; do juju run microceph/$i add-osd loop-spec=4G,1 ; done
          sleep 60
          juju ssh microceph/0 -- sudo ceph -s

      - name: Test successful upgrade
        run: |
          set -eux
          date
          target="reef/stable"
          juju config microceph snap-channel=$target
          sleep 60
          # Initial wait
          juju wait-for application microceph --query='forEach(units, unit => unit.workload-status=="active" && unit.agent-status=="idle")' --timeout=30m || true
          # Get status
          juju ssh microceph/0 -- sudo ceph -s
          juju ssh microceph/0 -- sudo microceph cluster list
          juju status
          # Fail if goal status not reached
          juju wait-for application microceph --query='forEach(units, unit => unit.workload-status=="active" && unit.agent-status=="idle")' --timeout=2m
          date
          # Test if we have expected snap releases
          juju exec -a microceph -- sudo snap info microceph
          cnt=$( juju exec -a microceph -- sudo snap info microceph | egrep "^tracking:" | fgrep -c $target )
          if [[ "$cnt" -ne "3" ]] ; then
            echo "Fail: expected 3 nodes at $target, got $cnt"
            exit -1
          fi

      - name: Test the set-pool-size action
        run: |
          set -eux
          juju ssh microceph/0 -- sudo ceph osd pool create mypool1
          juju ssh microceph/0 -- sudo ceph osd pool create mypool2
          juju run microceph/0 set-pool-size pools=mypool1,mypool2 size=1
          juju ssh microceph/0 -- sudo ceph osd pool get mypool1 size | fgrep -x "size: 1"
          juju ssh microceph/0 -- sudo ceph osd pool get mypool2 size | fgrep -x "size: 1"

      - name: Test that downgrade blocks
        run: |
          set -eux
          juju config microceph snap-channel=quincy/stable
          juju wait-for application microceph --query='status=="blocked"'
          juju status
          juju status blocked | egrep '^microceph/.*Cannot upgrade.*to quincy/stable'

      - name: Collect logs
        if: failure()
        run: ./tests/scripts/ci_helpers.sh collect_microceph_logs

      - name: Upload logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: microceph_juju_upgrade_test_logs
          path: logs
          retention-days: 30

      - name: Setup tmate session
        if: ${{ failure() && runner.debug }}
        uses: canonical/action-tmate@main

  juju-network-spaces-test:
    needs:
      - lint
      - unit-test
      - build
    name: Juju Network spaces test
    runs-on: [self-hosted, xlarge]
    steps:

      - name: Download charm
        uses: actions/download-artifact@v4
        with:
          name: charms
          path: ~/artifacts/

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup LXD
        uses: canonical/setup-lxd@v0.1.1
        with:
          # pin lxd since there were some recurring issues in recent releases.
          channel: 5.0/stable

      - name: Seed preliminary LXD profile
        run: ./tests/scripts/ci_helpers.sh seed_lxd_profile ./tests/scripts/assets/lxd-preseed.yaml

      - name: Install dependencies
        run: ./tests/scripts/ci_helpers.sh install_juju_simple

      - name: Configure Juju spaces
        run: |
          # Seed multi-interface profile with netplan config.
          ./tests/scripts/ci_helpers.sh seed_lxd_profile ./tests/scripts/assets/lxd-preseed-cloud-init.yaml
          # Configure Juju spaces
          ./tests/scripts/ci_helpers.sh setup_juju_spaces

      - name: Install MicroCeph charm
        run: |
          set -eux
          date
          mv ~/artifacts/microceph.charm ./tests/scripts/assets/
          juju deploy ./tests/scripts/assets/juju-spaces-bundle.yaml
          # wait for charm to bootstrap and OSD devices to enroll.
          sleep 10m
          juju status
          juju wait-for unit microceph/0 --query='workload-message=="(workload) charm is ready"' --timeout=20m
          bash ./tests/scripts/ci_helpers.sh check_osd_count microceph/0 3
          date

      - name: Validate the network configurations.
        run: ./tests/scripts/ci_helpers.sh verify_juju_spaces_config

      - name: Collect logs
        if: failure()
        run: ./tests/scripts/ci_helpers.sh collect_microceph_logs

      - name: Upload logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: microceph_juju_network_spaces_test_logs
          path: logs
          retention-days: 30

      - name: Setup tmate session
        if: ${{ failure() && runner.debug }}
        uses: canonical/action-tmate@main



  juju-mds-test:
    needs:
      - lint
      - unit-test
      - build
    name: Juju mds test
    runs-on: [self-hosted, xlarge]
    steps:

      - name: Download charm
        uses: actions/download-artifact@v4
        with:
          name: charms
          path: ~/artifacts/

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup LXD
        uses: canonical/setup-lxd@v0.1.1
        with:
          # pin lxd to LTS release.
          channel: 5.21/stable

      - name: Install dependencies
        run: ./tests/scripts/ci_helpers.sh install_deps

      - name: Install MicroCeph charm
        run: |
          set -eux
          date
          # constraints to deploy on virtual machine.
          juju deploy ~/artifacts/microceph.charm --storage osd-standalone='2G,3' --constraints="virt-type=virtual-machine root-disk=50G mem=8G"
          # wait for charm to bootstrap and OSD devices to enroll.
          juju wait-for unit microceph/0 --timeout '30m' --query='workload-message=="(workload) charm is ready"'
          bash ./tests/scripts/ci_helpers.sh check_osd_count microceph/0 3
          date

      - name: Add and relate CephFS charm
        run: |
          set -eux
          juju deploy ch:ceph-fs
          # wait for charm to bootstrap.
          juju wait-for unit ceph-fs/0 --query='workload-status=="blocked"' --timeout=30m
          juju integrate ceph-fs:ceph-mds microceph:mds
          # wait for filesystem creation
          juju wait-for application ceph-fs --query='name=="ceph-fs" && (status=="active" || status=="idle")' --timeout=10m
          filesystems=$(juju ssh microceph/0 -- "sudo microceph.ceph fs ls")
          if ! echo "$filesystems" | grep -E "ceph-fs" ; then
            echo "Failed to create the ceph-fs filesystem"
            juju ssh microceph/0 -- "sudo microceph.ceph fs ls"
            exit 1
          fi
          # check if the ceph-mds daemon is running
          juju ssh ceph-fs/0 -- 'sudo systemctl is-active ceph-mds@$HOSTNAME.service --quiet'

      - name: Collect logs
        if: failure()
        run: ./tests/scripts/ci_helpers.sh collect_microceph_logs

      - name: Upload logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: microceph_juju_mds_test_logs
          path: logs
          retention-days: 30

      - name: Setup tmate session
        if: ${{ failure() && runner.debug }}
        uses: canonical/action-tmate@main

  juju-storage-cluster-test:
    needs:
      - lint
      - unit-test
      - build
    name: Juju multi node storage test
    runs-on: [self-hosted, xlarge]
    steps:
      - name: Download charm
        uses: actions/download-artifact@v4
        with:
          name: charms
          path: ~/artifacts/

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup LXD
        uses: canonical/setup-lxd@v0.1.1
        with:
          # pin lxd to LTS release.
          channel: 5.21/stable

      - name: Install dependencies
        run: ./tests/scripts/ci_helpers.sh install_deps

      - name: Install MicroCeph charm
        run: |
          date
          mv ~/artifacts/microceph.charm ./microceph.charm
          juju deploy ./tests/bundles/multi_node_juju_storage.yaml
          # wait for charm to bootstrap and OSD devices to enroll.
          ./tests/scripts/ci_helpers.sh wait_for_microceph_bootstrap
          date

      - name: Show Juju status
        run: |
          set -eux
          juju status

      - name: Remove Unit microceph/2
        run: |
          set -x
          ./tests/scripts/ci_helpers.sh ensure_osd_count_on_host "juju.*\-2" 3
          ./tests/scripts/ci_helpers.sh remove_unit_wait "microceph/2"

          # sleep for some time
          sleep 1m

          ./tests/scripts/ci_helpers.sh ensure_osd_count_on_host "juju.*\-2" 0

      - name: Add another unit
        run: |
          set -x
          juju add-unit microceph -n 1
          sleep 60s
          juju wait-for unit microceph/3 --query='workload-message=="(workload) charm is ready"' --timeout=20m

           # "juju" substring is a part of all hosts, so it will fetch total OSD count
          ./tests/scripts/ci_helpers.sh ensure_osd_count_on_host "juju" 9

      - name: Collect logs
        if: failure()
        run: ./tests/scripts/ci_helpers.sh collect_microceph_logs

      - name: Upload logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: microceph_juju_storage_cluster_test_logs
          path: logs
          retention-days: 30

      - name: Setup tmate session
        if: ${{ failure() && runner.debug }}
        uses: canonical/action-tmate@main

  cos-integration-test:
    needs:
      - lint
      - unit-test
      - build
    name: Charm MicroCeph COS integration test
    runs-on: [self-hosted, xlarge, linux, amd64]
    steps:
      - name: Download charm
        uses: actions/download-artifact@v4
        with:
          name: charms
          path: ~/artifacts/

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup LXD
        uses: canonical/setup-lxd@v0.1.1
        with:
          # pin lxd to LTS release.
          channel: 5.21/stable

      - name: Install dependencies
        run: |
          ./tests/scripts/ci_helpers.sh install_deps
          sudo snap install microk8s --channel 1.32-strict/stable

      - name: Cleanup Docker
        run: ./tests/scripts/ci_helpers.sh cleanup_docker

      - name: Bootstrap K8s
        run: ./tests/scripts/ci_helpers.sh bootstrap_k8s

      - name: Bootstrap k8s controller
        run: ./tests/scripts/ci_helpers.sh bootstrap_k8s_controller

      - name: Deploy cos lite
        run: ./tests/scripts/ci_helpers.sh deploy_cos

      - name: Deploy cos lite
        run: ./tests/scripts/ci_helpers.sh check_http_endpoints_up
      
      - name: Deploy MicroCeph charm over LXD
        run: ./tests/scripts/ci_helpers.sh deploy_microceph

      - name: Deploy and Integrate grafana-agent
        run: ./tests/scripts/ci_helpers.sh deploy_grafana_agent

      - name: Test Metrics and Dashboards
        run: ./tests/scripts/ci_helpers.sh verify_o11y_services
          
      - name: Show Juju status
        run: |
          set -eux
          juju status

      - name: Collect logs
        if: failure()
        run: ./tests/scripts/ci_helpers.sh collect_microceph_logs || true

      - name: Upload logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: microceph_juju_storage_cluster_test_logs
          path: logs
          retention-days: 30

      - name: Setup tmate session
        if: ${{ failure() && runner.debug }}
        uses: canonical/action-tmate@main

